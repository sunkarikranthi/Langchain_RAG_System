{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d33eac8-cbfc-4a12-bdbe-4a925dde04b0",
   "metadata": {},
   "source": [
    "#### **Install requires dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc1d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pypdf\n",
    "# pip install langchain_community\n",
    "# pip install -U langchain-text-splitters\n",
    "# pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7791c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf7db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = PyPDFLoader(\"Leave_No_Context_Behind.pdf\")\n",
    "page = doc.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8beaabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "text_splitter = NLTKTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e8ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprint.\n",
      "\n",
      "Under review.\n",
      "\n",
      "Leave No Context Behind:\n",
      "Efficient Infinite Context Transformers with Infini-attention\n",
      "Tsendsuren Munkhdalai, Manaal Faruqui and Siddharth Gopal\n",
      "Google\n",
      "tsendsuren@google.com\n",
      "Abstract\n",
      "This work introduces an efficient method to scale Transformer-based Large\n",
      "Language Models (LLMs) to infinitely long inputs with bounded memory\n",
      "and computation.\n",
      "\n",
      "A key component in our proposed approach is a new at-\n",
      "tention technique dubbed Infini-attention.\n",
      "\n",
      "The Infini-attention incorporates\n",
      "a compressive memory into the vanilla attention mechanism and builds\n",
      "in both masked local attention and long-term linear attention mechanisms\n",
      "in a single Transformer block.\n",
      "\n",
      "We demonstrate the effectiveness of our\n",
      "approach on long-context language modeling benchmarks, 1M sequence\n",
      "length passkey context block retrieval and 500K length book summarization\n",
      "tasks with 1B and 8B LLMs.\n",
      "\n",
      "Our approach introduces minimal bounded\n",
      "memory parameters and enables fast streaming inference for LLMs.\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0609ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "genAI_model = GoogleGenerativeAIEmbeddings(google_api_key=\"AIzaSyAliBxWLI5AYRZGONXlqprqMtyhfYf30Ng\", model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166b214-456e-4c83-b912-1c8b15cef40c",
   "metadata": {},
   "source": [
    "#### Store the chunks in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1660abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(chunks, genAI_model, persist_directory=\"./chromadb\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707b23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = Chroma(persist_directory=\"./chromadb\", embedding_function = genAI_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d405b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddef651",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    \n",
    "    # System_Message Prompt Template\n",
    "    SystemMessage(content=\"\"\"You are a nice polite AI Bot. \n",
    "    Provide assistance to the user based on the context asked by the user.\n",
    "    Make sure your answers are relevant to the context.\"\"\"),\n",
    "    \n",
    "    # Human_Message Prompt Template\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer: \"\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=\"AIzaSyAliBxWLI5AYRZGONXlqprqMtyhfYf30Ng\", model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da907f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ade762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | chat_template | chat_model | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abdcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "model_response = rag_chain.invoke(\"explain about Context Transformers with Infini-attention\")\n",
    "Markdown(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = rag_chain.invoke(\"explain about Long-term context injection\")\n",
    "Markdown(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = rag_chain.invoke(\"Summarize the paper and expain it briefly\")\n",
    "Markdown(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f246d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
